{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Digit Classification with KNN and Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you'll implement your own image recognition system for classifying digits. Read through the code and the instructions carefully and add your own code where indicated. Each problem can be addressed succinctly with the included packages -- please don't add any more. Grading will be based on writing clean, commented code, along with a few short answers.\n",
    "\n",
    "As always, you're welcome to work on the project in groups and discuss ideas on the course wall, but <b> please prepare your own write-up (with your own code). </b>\n",
    "\n",
    "If you're interested, check out these links related to digit recognition:\n",
    "\n",
    "Yann Lecun's MNIST benchmarks: http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "Stanford Streetview research and data: http://ufldl.stanford.edu/housenumbers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# Import a bunch of libraries.\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set the randomizer seed so results are the same each time.\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data. Notice that we are splitting the data into training, development, and test. We also have a small subset of the training data called mini_train_data and mini_train_labels that you should use in all the experiments below, unless otherwise noted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (70000, 784)\n",
      "label shape: (70000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the digit data either from mldata.org, or once downloaded to data_home, from disk. The data is about 53MB so this cell\n",
    "# should take a while the first time your run it.\n",
    "mnist = fetch_mldata('MNIST original', data_home='~/datasets/mnist')\n",
    "X, Y = mnist.data, mnist.target\n",
    "\n",
    "# Rescale grayscale values to [0,1].\n",
    "X = X / 255.0\n",
    "\n",
    "# Shuffle the input: create a random permutation of the integers between 0 and the number of data points and apply this\n",
    "# permutation to X and Y.\n",
    "# NOTE: Each time you run this cell, you'll re-shuffle the data, resulting in a different ordering.\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "print ('data shape: ', X.shape)\n",
    "print ('label shape:', Y.shape)\n",
    "\n",
    "# Set some variables to hold test, dev, and training data.\n",
    "test_data, test_labels = X[61000:], Y[61000:]\n",
    "dev_data, dev_labels = X[60000:61000], Y[60000:61000]\n",
    "train_data, train_labels = X[:60000], Y[:60000]\n",
    "mini_train_data, mini_train_labels = X[:1000], Y[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Create a 10x10 grid to visualize 10 examples of each digit. Python hints:\n",
    "\n",
    "- plt.rc() for setting the colormap, for example to black and white\n",
    "- plt.subplot() for creating subplots\n",
    "- plt.imshow() for rendering a matrix\n",
    "- np.array.reshape() for reshaping a 1D feature vector into a 2D matrix (for rendering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAADuCAYAAAB4fc+hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bd76c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#def P1(num_examples=10):\n",
    "\n",
    "### STUDENT START ###\n",
    "    \n",
    "\n",
    "def P1(num_examples=10):\n",
    "    digits = [col for i in range(10) \n",
    "                  for col in [index for index, label in enumerate(mini_train_labels) if label==i][0:num_examples]]   \n",
    "    fig, ax = plt.subplots(10, num_examples)\n",
    "    plt.style.use(\"grayscale\") # grayscale\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "    for index, digit in enumerate(ax.flat):\n",
    "        digit.imshow(np.reshape(mini_train_data[digits[index]], (28,28)))\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "#P1(10)\n",
    "\n",
    "P1(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Evaluate a K-Nearest-Neighbors model with k = [1,3,5,7,9] using the mini training set. Report accuracy on the dev set. For k=1, show precision, recall, and F1 for each label. Which is the most difficult digit?\n",
    "\n",
    "- KNeighborsClassifier() for fitting and predicting\n",
    "- classification_report() for producing precision, recall, F1 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k=1\n",
      "0.888\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.98      0.94        99\n",
      "        1.0       0.89      1.00      0.94       105\n",
      "        2.0       0.99      0.79      0.88       102\n",
      "        3.0       0.77      0.87      0.82        86\n",
      "        4.0       0.89      0.82      0.85       104\n",
      "        5.0       0.93      0.84      0.88        91\n",
      "        6.0       0.94      0.96      0.95        98\n",
      "        7.0       0.89      0.92      0.90       113\n",
      "        8.0       0.94      0.88      0.91        96\n",
      "        9.0       0.78      0.82      0.80       106\n",
      "\n",
      "avg / total       0.89      0.89      0.89      1000\n",
      "\n",
      "\n",
      "k=3\n",
      "0.878\n",
      "\n",
      "k=5\n",
      "0.869\n",
      "\n",
      "k=7\n",
      "0.865\n",
      "\n",
      "k=9\n",
      "0.863\n"
     ]
    }
   ],
   "source": [
    "#def P2(k_values):\n",
    "\n",
    "### STUDENT START ###\n",
    "\n",
    "def P2(k_values):\n",
    "    for k in k_values:\n",
    "        print(\"\\nk=\"+str(k))\n",
    "        neightbour = KNeighborsClassifier(n_neighbors = k)\n",
    "        neightbour.fit(mini_train_data, mini_train_labels)\n",
    "        prediction = neightbour.predict(dev_data)\n",
    "        matches = prediction == dev_labels  \n",
    "        accuracy = np.mean(matches)\n",
    "        print(accuracy)\n",
    "        \n",
    "        # Report accuracy for k = 1\n",
    "        \n",
    "        if k==1:\n",
    "            print(classification_report(dev_labels,prediction))\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "#P2(k_values)\n",
    "\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "\n",
    "P2(k_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: Based on f1-score, 9 (9.0) is the most difficult digit since the f1-score is lowest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Using k=1, report dev set accuracy for the training set sizes below. Also, measure the amount of time needed for prediction with each training size.\n",
    "\n",
    "- time.time() gives a wall clock value you can use for timing operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_sizes=100\n",
      "0.72\n",
      "run time is 0.19711995124816895\n",
      "\n",
      "\n",
      "train_sizes=200\n",
      "0.786\n",
      "run time is 0.23239684104919434\n",
      "\n",
      "\n",
      "train_sizes=400\n",
      "0.841\n",
      "run time is 0.7964239120483398\n",
      "\n",
      "\n",
      "train_sizes=800\n",
      "0.884\n",
      "run time is 1.024029016494751\n",
      "\n",
      "\n",
      "train_sizes=1600\n",
      "0.902\n",
      "run time is 1.9452621936798096\n",
      "\n",
      "\n",
      "train_sizes=3200\n",
      "0.926\n",
      "run time is 4.236318826675415\n",
      "\n",
      "\n",
      "train_sizes=6400\n",
      "0.937\n",
      "run time is 8.259067058563232\n",
      "\n",
      "\n",
      "train_sizes=12800\n",
      "0.959\n",
      "run time is 16.2703218460083\n",
      "\n",
      "\n",
      "train_sizes=25000\n",
      "0.97\n",
      "run time is 33.47624325752258\n",
      "\n",
      "[0.72, 0.786, 0.841, 0.884, 0.902, 0.926, 0.937, 0.959, 0.97]\n"
     ]
    }
   ],
   "source": [
    "#def P3(train_sizes, accuracies):\n",
    "\n",
    "### STUDENT START ###\n",
    "def P3(train_sizes, accuracies):\n",
    "    for i in train_sizes:\n",
    "        print(\"\\ntrain_sizes=\"+str(i))\n",
    "        start = time.time()\n",
    "        neightbour = KNeighborsClassifier(n_neighbors = 1)\n",
    "        neightbour.fit(train_data[:i],train_labels[:i])\n",
    "        prediction = neightbour.predict(dev_data)\n",
    "        matches = prediction == dev_labels  \n",
    "        accuracy = np.mean(matches)\n",
    "        end = time.time()\n",
    "        print(accuracy)\n",
    "        print(\"run time is \" + str(end - start) + \"\\n\")\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "train_sizes = [100, 200, 400, 800, 1600, 3200, 6400, 12800, 25000]\n",
    "accuracies = []\n",
    "#P3(train_sizes, accuracies)\n",
    "\n",
    "P3(train_sizes, accuracies)\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Fit a regression model that predicts accuracy from training size. What does it predict for n=60000? What's wrong with using regression here? Can you apply a transformation that makes the predictions more reasonable?\n",
    "\n",
    "- Remember that the sklearn fit() functions take an input matrix X and output vector Y. So each input example in X is a vector, even if it contains only a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standard Regression predicted accuracy: 1.24307226036\n",
      "\n",
      "Logistic transformation predicted accuracy: 0.9988179603283155\n"
     ]
    }
   ],
   "source": [
    "#def P4():\n",
    "\n",
    "### STUDENT START ###\n",
    "def P4(train_sizes, accuracies, n):\n",
    "    regr = LinearRegression()\n",
    "    regr.fit(np.reshape(train_sizes,(-1,1)), accuracies)\n",
    "    predicted = regr.predict(np.reshape(n,(-1,1)))\n",
    "    print(\"\\nStandard Regression predicted accuracy: \" + str(predicted[0]))\n",
    "    \n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "train_sizes = [100, 200, 400, 800, 1600, 3200, 6400, 12800, 25000]\n",
    "accuracies = [0.72, 0.786, 0.841, 0.884, 0.902, 0.926, 0.937, 0.959, 0.97]\n",
    "n=60000\n",
    "\n",
    "#P4()\n",
    "P4(train_sizes, accuracies, n)\n",
    "\n",
    "### Logit Transformation ###\n",
    "\n",
    "def P4_transformed(train_sizes, accuracies, n):\n",
    "    \n",
    "    accLogit = [np.log(val/(1-val)) for val in accuracies]\n",
    "    regr = LinearRegression()\n",
    "    regr.fit(np.reshape(train_sizes,(-1,1)), accLogit)\n",
    "    log = regr.predict(np.reshape(n,(1,-1)))\n",
    "    logpredic = float(np.exp(log)/(np.exp(log) + 1))\n",
    "    print(\"\\nLogistic transformation predicted accuracy: \" + str(logpredic))\n",
    "   \n",
    "P4_transformed(train_sizes, accuracies, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: Standard form is giving a predicted accuracy of 1.24, which is bigger than 1 and is wrong as any acurracy should be 1 at best. Simple regression will give such answer as the predicted value is not bounded. To correct for the nature that Y should be bounded between 0 and 1, a logit transformation would be useful\n",
    "\n",
    "The new way of predicting will give an accuracy of 0.999. \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a 1-NN and output a confusion matrix for the dev data. Use the confusion matrix to identify the most confused pair of digits, and display a few example mistakes.\n",
    "\n",
    "- confusion_matrix() produces a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 99   0   0   0   0   0   0   0   0   0]\n",
      " [  0 105   0   0   0   0   0   0   0   0]\n",
      " [  1   0  98   2   0   0   0   1   0   0]\n",
      " [  0   0   0  83   0   1   0   0   1   1]\n",
      " [  0   0   0   0 102   0   0   0   0   2]\n",
      " [  1   0   0   0   0  88   0   0   1   1]\n",
      " [  1   0   0   0   1   0  96   0   0   0]\n",
      " [  0   0   1   0   0   0   0 111   0   1]\n",
      " [  1   0   1   2   0   2   1   0  89   0]\n",
      " [  0   0   0   0   0   0   0   0   0 106]] \n",
      "\n",
      "[[ 0.96  0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.01  0.    0.98  0.02  0.    0.    0.    0.01  0.    0.  ]\n",
      " [ 0.    0.    0.    0.95  0.    0.01  0.    0.    0.01  0.01]\n",
      " [ 0.    0.    0.    0.    0.99  0.    0.    0.    0.    0.02]\n",
      " [ 0.01  0.    0.    0.    0.    0.97  0.    0.    0.01  0.01]\n",
      " [ 0.01  0.    0.    0.    0.01  0.    0.99  0.    0.    0.  ]\n",
      " [ 0.    0.    0.01  0.    0.    0.    0.    0.99  0.    0.01]\n",
      " [ 0.01  0.    0.01  0.02  0.    0.02  0.01  0.    0.98  0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.95]] \n",
      "\n",
      "6.0 is mis-predicted as 4.0\n",
      "7.0 is mis-predicted as 2.0\n",
      "8.0 is mis-predicted as 3.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAB3CAYAAAA0LjqhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGQCUoCADgBL/A5p8rpIVJrdFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12508b7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#def P5():\n",
    "\n",
    "### STUDENT START ###\n",
    "\n",
    "def P5():\n",
    "    neightbour = KNeighborsClassifier(n_neighbors=1)\n",
    "    neightbour.fit(train_data,train_labels)\n",
    "    prediction = neightbour.predict(dev_data)\n",
    "    print(confusion_matrix(dev_labels,prediction), \"\\n\") \n",
    "    \n",
    "    # normalize the confusion_matrix to see which pair is the most confused ones\n",
    "    \n",
    "    normalizer =[]\n",
    "    for i in range(len(confusion_matrix(dev_labels,prediction))):\n",
    "        num = 0\n",
    "        for j in range(len(confusion_matrix(dev_labels,prediction))):\n",
    "            num += confusion_matrix(dev_labels,prediction)[j][i] \n",
    "        normalizer.append(num)\n",
    "    \n",
    "    output = (confusion_matrix(dev_labels,prediction))/normalizer\n",
    "    print(output.round(decimals = 2), \"\\n\")\n",
    "    \n",
    "    # the highest % of mis-matched pair is 2%, there are a few of them, for eaxmple, 3 with 8\n",
    "    \n",
    "    matches = prediction == dev_labels\n",
    "    SomeMistakes = [index for index, x in enumerate(matches) if x == False][0:3]\n",
    "    \n",
    "    # test 3 wrongly matched samples\n",
    "    for i in range(3):\n",
    "        print(str(dev_labels[SomeMistakes[i]]) + \" is mis-predicted as \" + str(prediction[SomeMistakes[i]]))\n",
    "    \n",
    "    # plot image\n",
    "        \n",
    "    fig, ax = plt.subplots(1, 3)\n",
    "    plt.style.use(\"grayscale\")\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "    for index, digit in enumerate(ax.flat):\n",
    "        digit.imshow(np.reshape(dev_data[SomeMistakes[index]], (28,28)))  \n",
    "    \n",
    "    \n",
    "### STUDENT END ###\n",
    "\n",
    "#P5()\n",
    "\n",
    "P5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) A common image processing technique is to smooth an image by blurring. The idea is that the value of a particular pixel is estimated as the weighted combination of the original value and the values around it. Typically, the blurring is Gaussian -- that is, the weight of a pixel's influence is determined by a Gaussian function over the distance to the relevant pixel.\n",
    "\n",
    "Implement a simplified Gaussian blur by just using the 8 neighboring pixels: the smoothed value of a pixel is a weighted combination of the original value and the 8 neighboring values. Try applying your blur filter in 3 ways:\n",
    "- preprocess the training data but not the dev data\n",
    "- preprocess the dev data but not the training data\n",
    "- preprocess both training and dev data\n",
    "\n",
    "Note that there are Guassian blur filters available, for example in scipy.ndimage.filters. You're welcome to experiment with those, but you are likely to get the best results with the simplified version I described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original gives an accuracy : 0.864\n",
      "Preprocess only the training data gives an accuracy : 0.892\n",
      "Preprocess only the dev data gives an accuracy : 0.844\n",
      "Preprocess both data gives an accuracy : 0.89\n"
     ]
    }
   ],
   "source": [
    "#def P6():\n",
    "    \n",
    "### STUDENT START ###\n",
    "\n",
    "def P6(data_to_transform):\n",
    "    rs=[np.reshape(data, (28,28)) for data in data_to_transform]\n",
    "    new = []\n",
    "\n",
    "    for digit in range(len(rs)):\n",
    "        blur = [[0 for x in range(28)] for y in range(28)] \n",
    "        for col in range(28):\n",
    "            for row in range(28):\n",
    "                \n",
    "                # Corner Cases\n",
    "                if col == 0 and row == 0:\n",
    "                    blur[row][col] = (rs[digit][row][col] + rs[digit][row + 1][col + 1]\n",
    "                                    + rs[digit][row + 1][col] + rs[digit][row][col + 1]) / 4\n",
    "                    \n",
    "                # Corner Cases\n",
    "                elif col == 27 and row == 0:\n",
    "                    blur[row][col] = (rs[digit][row][col] + rs[digit][row + 1][col - 1]\n",
    "                                    + rs[digit][row + 1][col] + rs[digit][row][col - 1])/4\n",
    "                \n",
    "                # Corner Cases\n",
    "                elif col == 0 and row == 27:\n",
    "                    blur[row][col] = (rs[digit][row][col] + rs[digit][row - 1][col + 1]\n",
    "                                    + rs[digit][row - 1][col] + rs[digit][row][col + 1]) / 4\n",
    "                         \n",
    "                # Corner Cases\n",
    "                elif col == 27 and row == 27:\n",
    "                    blur[row][col] = (rs[digit][row][col] + rs[digit][row-1][col-1]\n",
    "                                    +rs[digit][row - 1][col]+rs[digit][row][col-1]) / 4\n",
    "                    \n",
    "                # On the Edge Cases\n",
    "                elif col == 0:\n",
    "                    blur[row][col] = (rs[digit][row][col] + rs[digit][row + 1][col + 1]\n",
    "                                    + rs[digit][row - 1][col +1] + rs[digit][row + 1][col]\n",
    "                                    + rs[digit][row - 1][col] + rs[digit][row][col + 1]) / 6\n",
    "                # On the Edge Cases\n",
    "                elif row == 0:\n",
    "                    blur[row][col] = (rs[digit][row][col]+rs[digit][row + 1][col + 1]\n",
    "                                    +rs[digit][row + 1][col - 1]+rs[digit][row + 1][col]\n",
    "                                    + rs[digit][row][col + 1] + rs[digit][row][col - 1]) / 6\n",
    "                # On the Edge Cases\n",
    "                elif col == 27:\n",
    "                    blur[row][col] = (rs[digit][row][col] + rs[digit][row - 1][col - 1]\n",
    "                                    + rs[digit][row + 1][col - 1]+rs[digit][row + 1][col]\n",
    "                                    + rs[digit][row - 1][col] + rs[digit][row][col - 1]) / 6\n",
    "                # On the Edge Cases\n",
    "                elif row == 27:\n",
    "                    blur[row][col] = (rs[digit][row][col]+ rs[digit][row - 1][col - 1]\n",
    "                                    + rs[digit][row-1][col + 1]+rs[digit][row - 1][col]\n",
    "                                    + rs[digit][row][col + 1]+rs[digit][row][col - 1]) / 6\n",
    "                # Normal Cases\n",
    "                else:\n",
    "                    blur[row][col] = (rs[digit][row][col] + rs[digit][row + 1][col + 1]+rs[digit][row - 1][col - 1]\n",
    "                                    + rs[digit][row + 1][col - 1] + rs[digit][row - 1][col + 1] + rs[digit][row + 1][col]\n",
    "                                    + rs[digit][row - 1][col] + rs[digit][row][col + 1] + rs[digit][row][col - 1]) / 9\n",
    "        new.append(blur)\n",
    "    return(new)\n",
    "\n",
    "def Knn(k, train, train_label, dev, dev_label):\n",
    "    neightbour = KNeighborsClassifier(n_neighbors=k)\n",
    "    neightbour.fit(train,train_label)\n",
    "    prediction = neightbour.predict(dev)\n",
    "    matches = prediction == dev_label\n",
    "    accuracy = np.mean(matches)\n",
    "    return(accuracy)\n",
    "    \n",
    "    \n",
    "# blurring train data and dev data\n",
    "new_dev = P6(dev_data)\n",
    "new_dev = np.reshape(new_dev,(len(dev_labels), -1))\n",
    "new_train = P6(mini_train_data)\n",
    "new_train = np.reshape(new_train,(len(mini_train_labels), -1))\n",
    "\n",
    "# original\n",
    "print(\"Original gives an accuracy :\", Knn(2, mini_train_data, mini_train_labels, dev_data, dev_labels))\n",
    "\n",
    "# preprocess the training data but not the dev data\n",
    "print(\"Preprocess only the training data gives an accuracy :\", Knn(2, new_train, \n",
    "                                                                     mini_train_labels, dev_data, dev_labels))\n",
    "\n",
    "# preprocess the dev data but not the training data\n",
    "print(\"Preprocess only the dev data gives an accuracy :\",Knn(2, mini_train_data,\n",
    "                                                               mini_train_labels, new_dev, dev_labels))\n",
    "\n",
    "# preprocess both training and dev data\n",
    "print(\"Preprocess both data gives an accuracy :\",Knn(2, new_train, mini_train_labels, new_dev, dev_labels))\n",
    "\n",
    "### STUDENT END ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: It seems that preprocess the training data but not the dev data gives a slightly higher accuray. But that difference is very marginal. Thus, the result might be different in another iteration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7) Fit a Naive Bayes classifier and report accuracy on the dev data. Remember that Naive Bayes estimates P(feature|label). While sklearn can handle real-valued features, let's start by mapping the pixel values to either 0 or 1. You can do this as a preprocessing step, or with the binarize argument. With binary-valued features, you can use BernoulliNB. Next try mapping the pixel values to 0, 1, or 2, representing white, grey, or black. This mapping requires MultinomialNB. Does the multi-class version improve the results? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Accuracy: 0.811\n",
      "Multinomial Accuracy: 0.796\n"
     ]
    }
   ],
   "source": [
    "#def P7():\n",
    "\n",
    "### STUDENT START ###\n",
    "\n",
    "def P7():\n",
    "    bernoulli = BernoulliNB(binarize=.1)\n",
    "    bernoulli.fit(mini_train_data, mini_train_labels)\n",
    "    prediction = bernoulli.predict(dev_data)\n",
    "    matches = prediction == dev_labels\n",
    "    accuracy = float(len([match for match in matches if match == True])) / float(len(matches))\n",
    "    print(\"Bernoulli Accuracy: \" + str(accuracy))\n",
    "\n",
    "    multi_train_data = mini_train_data\n",
    "    # for \n",
    "    for i in range(len(multi_train_data)):\n",
    "        for j in range(len(multi_train_data[i])):\n",
    "            if multi_train_data[i][j] >= 0.12:\n",
    "                multi_train_data[i][j] = 2\n",
    "            elif multi_train_data[i][j] >= 0.33:\n",
    "                multi_train_data[i][j] = 1\n",
    "            else:\n",
    "                multi_train_data[i][j] = 0\n",
    "    Multinomial = MultinomialNB()\n",
    "    Multinomial.fit(multi_train_data, mini_train_labels)\n",
    "    prediction = Multinomial.predict(dev_data)\n",
    "    matches = prediction == dev_labels\n",
    "    accuracy = np.mean(matches)\n",
    "    print(\"Multinomial Accuracy: \" + str(accuracy))\n",
    "    \n",
    "### STUDENT END ###\n",
    "\n",
    "P7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: The Bernoulli's accuracy is better than Multinomial accuracy. Having 3 classes doesn't make it better than only having 2 classes which is the difference here. The grey layer probably make it even difficult to classify the digits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(8) Use GridSearchCV to perform a search over values of alpha (the Laplace smoothing parameter) in a Bernoulli NB model. What is the best value for alpha? What is the accuracy when alpha=0? Is this what you'd expect?\n",
    "\n",
    "- Note that GridSearchCV partitions the training data so the results will be a bit different than if you used the dev data for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/naive_bayes.py:801: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = (np.log(smoothed_fc) -\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/naive_bayes.py:801: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = (np.log(smoothed_fc) -\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/naive_bayes.py:820: RuntimeWarning: divide by zero encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/naive_bayes.py:801: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = (np.log(smoothed_fc) -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.001}\n",
      "The Alpha's Accuracy: 0.814\n",
      "\n",
      "\n",
      "[mean: 0.09200, std: 0.00080, params: {'alpha': 0.0}, mean: 0.82400, std: 0.01626, params: {'alpha': 0.0001}, mean: 0.82500, std: 0.01531, params: {'alpha': 0.001}, mean: 0.82500, std: 0.01507, params: {'alpha': 0.01}, mean: 0.82000, std: 0.01903, params: {'alpha': 0.1}, mean: 0.81400, std: 0.01236, params: {'alpha': 0.5}, mean: 0.80700, std: 0.00717, params: {'alpha': 1.0}, mean: 0.79900, std: 0.01046, params: {'alpha': 2.0}, mean: 0.73900, std: 0.01789, params: {'alpha': 10.0}]\n"
     ]
    }
   ],
   "source": [
    "#def P8(alphas):\n",
    "\n",
    "### STUDENT START ###\n",
    "\n",
    "def P8(alphas):\n",
    "    bernoulli =BernoulliNB(binarize=.1)\n",
    "    clf = GridSearchCV(bernoulli, alphas)\n",
    "    dog = clf.fit(mini_train_data, mini_train_labels)\n",
    "    pred = clf.predict(dev_data)\n",
    "    print(dog.best_params_)\n",
    "    matches = pred == dev_labels\n",
    "    accuracy = np.mean(matches)\n",
    "    print(\"The Alpha's Accuracy: \" + str(accuracy))\n",
    "    print(\"\\n\")\n",
    "    return(clf.grid_scores_)\n",
    "\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "alphas = {'alpha': [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0]}\n",
    "nb = P8(alphas)\n",
    "print(nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: The accuracy is 0.814 for alpha = 0.001. When the alpha = 0.01, the mean accuracy is 0.092. This is extremely low. When alpha = 0, it means there is no laplace smoothing and without it, there will be feature values shown in our testing set which is not appeaered in the training sets. As a result, the conditional probability of seeing this value given a certain digit label is zero, so examples which would otherwise easily to be classified will have their likelihoods affected by these values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(9) Try training a model using GuassianNB, which is intended for real-valued features, and evaluate on the dev data. You'll notice that it doesn't work so well. Try to diagnose the problem. You should be able to find a simple fix that returns the accuracy to around the same rate as BernoulliNB. Explain your solution.\n",
    "\n",
    "Hint: examine the parameters estimated by the fit() method, theta\\_ and sigma\\_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Accuracy: 0.551\n",
      "Gaussian Accuracy with estimated parameters added: 0.036\n"
     ]
    }
   ],
   "source": [
    "#def P9():\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "def P9():\n",
    "    groups = {}\n",
    "    for i in range(len(mini_train_data)-1):\n",
    "        if mini_train_labels[i] in groups:\n",
    "            groups[mini_train_labels[i]] = np.concatenate((groups[mini_train_labels[i]],[mini_train_data[i]]), axis=0)\n",
    "        else:\n",
    "            groups[mini_train_labels[i]] = [mini_train_data[i]]\n",
    "\n",
    "    theta = np.array([[sum(i)/len(group) for i in zip(*group)] for key, group in groups.items()])\n",
    "    sigma = np.array([[max(.1, np.var(i)) for i in zip(*group)] for key, group in groups.items()])\n",
    " \n",
    "    Garussian = GaussianNB()\n",
    "    Garussian.fit(mini_train_data, mini_train_labels)\n",
    "    prediction = Garussian.predict(dev_data)\n",
    "    matches = prediction == dev_labels\n",
    "    accuracy = np.mean(matches)\n",
    "    print(\"Gaussian Accuracy: \" + str(accuracy))\n",
    "    \n",
    "    Garussian.sigma_=sigma\n",
    "    Garussian.theta_=theta\n",
    "    prediction = Garussian.predict(dev_data)\n",
    "    matches = prediction == dev_labels\n",
    "    accuracy = np.mean(matches)\n",
    "    print(\"Gaussian Accuracy with estimated parameters added: \" + str(accuracy))\n",
    "    \n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "gnb = P9()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(10) Because Naive Bayes is a generative model, we can use the trained model to generate digits. Train a BernoulliNB model and then generate a 10x20 grid with 20 examples of each digit. Because you're using a Bernoulli model, each pixel output will be either 0 or 1. How do the generated digits compare to the training digits?\n",
    "\n",
    "- You can use np.random.rand() to generate random numbers from a uniform distribution\n",
    "- The estimated probability of each pixel is stored in feature\\_log\\_prob\\_. You'll need to use np.exp() to convert a log probability back to a probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Accuracy: 0.811\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAADuCAYAAABvX19oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/D/jS42vQpuZkQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12f4a8c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def P10(num_examples):\n",
    "\n",
    "### STUDENT START ###\n",
    "\n",
    "    bernoulli = BernoulliNB(binarize=.1)\n",
    "    bernoulli.fit(mini_train_data, mini_train_labels)\n",
    "    prediction = bernoulli.predict(dev_data)\n",
    "    matches = prediction == dev_labels\n",
    "    accuracy=np.mean(matches)\n",
    "    print(\"Bernoulli Accuracy: \" + str(accuracy))\n",
    "\n",
    "\n",
    "#convert a log probability to a probability\n",
    "    newSample = np.exp(bernoulli.feature_log_prob_)\n",
    "\n",
    "    import random\n",
    "    \n",
    "#randomly picking numbers from a list with given probabilities\n",
    "    def random_pick(some_list, probabilities):\n",
    "        x = np.random.rand(1, 1)\n",
    "        cumulative_probability = 0.0\n",
    "        for item, item_probability in zip(some_list, probabilities):\n",
    "            cumulative_probability += item_probability\n",
    "            if x < cumulative_probability: break\n",
    "        return item\n",
    "    \n",
    "# Generating 20 sample from each digit using the probability generated above\n",
    "\n",
    "    newSample = [[random_pick([1,0],[prob, 1-prob]) for prob in digit] for i in range(20) for digit in newSample]\n",
    "\n",
    "    fig, ax = plt.subplots(20, 10)\n",
    "    plt.style.use(\"grayscale\")\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "    for index, digit in enumerate(ax.flat):\n",
    "        digit.imshow(np.reshape(newSample[index], (28,28)))\n",
    "\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "P10(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: These digits look more \"random\" than the training digits. This makes sense to me because now the digit is generated randomlly, given the probability of the training set over the region. Each digit has a random change of being black or white and thus for it's less recognizable than the original training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(11) Remember that a strongly calibrated classifier is rougly 90% accurate when the posterior probability of the predicted class is 0.9. A weakly calibrated classifier is more accurate when the posterior is 90% than when it is 80%. A poorly calibrated classifier has no positive correlation between posterior and accuracy.\n",
    "\n",
    "Train a BernoulliNB model with a reasonable alpha value. For each posterior bucket (think of a bin in a histogram), you want to estimate the classifier's accuracy. So for each prediction, find the bucket the maximum posterior belongs to and update the \"correct\" and \"total\" counters.\n",
    "\n",
    "How would you characterize the calibration for the Naive Bayes model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Accuracy: 0.811 \n",
      "\n",
      "p(pred) <= 0.5000000000000    total =   2    accuracy = 0.500\n",
      "p(pred) <= 0.9000000000000    total =  39    accuracy = 0.359\n",
      "p(pred) <= 0.9990000000000    total =  83    accuracy = 0.398\n",
      "p(pred) <= 0.9999900000000    total =  62    accuracy = 0.500\n",
      "p(pred) <= 0.9999999000000    total =  61    accuracy = 0.754\n",
      "p(pred) <= 0.9999999990000    total =  77    accuracy = 0.727\n",
      "p(pred) <= 0.9999999999900    total =  61    accuracy = 0.738\n",
      "p(pred) <= 0.9999999999999    total =  58    accuracy = 0.862\n",
      "p(pred) <= 1.0000000000000    total = 557    accuracy = 0.961\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAGICAYAAABftqcbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12efe12b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#def P11(buckets, correct, total):\n",
    "    \n",
    "### STUDENT START ###\n",
    "\n",
    "def BucketIndex(prob, buckets):\n",
    "    for i in range(len(buckets)):\n",
    "        \n",
    "        if i == 0:\n",
    "            if prob < buckets[i]:\n",
    "                return i\n",
    "            \n",
    "        elif i == len(buckets) - 1:\n",
    "            if prob >= buckets[i]:\n",
    "                return i\n",
    "            \n",
    "        else:\n",
    "            if prob >= buckets[i-1] and prob < buckets[i]:\n",
    "                return i\n",
    "    return i\n",
    "\n",
    "def P11(buckets, correct, total):\n",
    "\n",
    "    bernoulli = BernoulliNB(binarize = .1)\n",
    "    bernoulli.fit(mini_train_data, mini_train_labels)\n",
    "    prediction = bernoulli.predict(dev_data)\n",
    "    matches = prediction == dev_labels\n",
    "    accuracy = np.mean(matches)\n",
    "    print(\"Bernoulli Accuracy: \" + str(accuracy), \"\\n\")\n",
    "\n",
    "    probSet = bernoulli.predict_proba(dev_data)\n",
    "    predictions = bernoulli.predict(dev_data)\n",
    "\n",
    "    for index, probs in enumerate(probSet):\n",
    "        prob = np.amax(probs)\n",
    "        bucketIndex = BucketIndex(prob,buckets)\n",
    "        total[bucketIndex] += 1\n",
    "        if predictions[index] == dev_labels[index]:\n",
    "            correct[bucketIndex] += 1\n",
    "\n",
    "    ratios = [float(x) / float(y) if x!=0 else 0 for x,y in zip(correct,total)]\n",
    "    for i in range(len(buckets)):\n",
    "        accuracy = 0.0\n",
    "        if (total[i] > 0): accuracy = float(correct[i]) / float(total[i])\n",
    "        print('p(pred) <= %.13f    total = %3d    accuracy = %.3f' %(buckets[i], total[i], accuracy))\n",
    "\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    N = len(ratios)\n",
    "\n",
    "    ind = np.arange(N)                \n",
    "    width = 0.5                 \n",
    "    rects1 = ax.bar(ind, ratios, width,\n",
    "                    color='black',\n",
    "                    error_kw = dict(elinewidth = 0,ecolor='red'))\n",
    "    \n",
    "    ax.set_xlim(-width,len(ind)+width)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_ylabel('Accuracy', fontsize = 15)\n",
    "    ax.set_title('Accuracy Per Posterior Probability Bucket')\n",
    "    xTickMarks = buckets\n",
    "    ax.set_xticks(ind + width)\n",
    "    xtickNames = ax.set_xticklabels(xTickMarks)\n",
    "    plt.setp(xtickNames, rotation = 90, fontsize = 15)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "buckets = [0.5, 0.9, 0.999, 0.99999, 0.9999999, 0.999999999, 0.99999999999, 0.9999999999999, 1.0]\n",
    "correct = [0 for i in buckets]\n",
    "total = [0 for i in buckets]\n",
    "\n",
    "P11(buckets, correct, total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: This classifier would be a weakly calibrated one. In the bar chart, we can see the accuracy is below .4 when the posterior probability is within the <0.9 bucket. Since there is a postive correlation between posterior probability and accuracy as accuracy reaches 100% when posterior probability goes to 1. Thus, the classifier is not a poorly calibrated one either. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(12) EXTRA CREDIT\n",
    "\n",
    "Try designing extra features to see if you can improve the performance of Naive Bayes on the dev set. Here are a few ideas to get you started:\n",
    "- Try summing the pixel values in each row and each column.\n",
    "- Try counting the number of enclosed regions; 8 usually has 2 enclosed regions, 9 usually has 1, and 7 usually has 0.\n",
    "\n",
    "Make sure you comment your code well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 0.813\n",
      "Adding Pixel Count Accuray: 0.823\n",
      "Adding count pixel improves the accuracy by: 0.01\n",
      "Original Accuracy: 0.813\n",
      "Adding count room  Accuray: 0.823\n",
      "Adding count room improves the accuracy by: 0.01\n",
      "Original Accuracy: 0.813\n",
      "Adding Both Accuray: 0.832\n",
      "Adding both improves the accuracy by: 0.019\n"
     ]
    }
   ],
   "source": [
    "#def P12():\n",
    "\n",
    "### STUDENT START ###\n",
    "\n",
    "# testing the accuracy changes for 1)Original Model 2)Adding Pixel Values 3)Adding no.of Rooms 4) Adding both 3) & 4)\n",
    "\n",
    "# Count room methodology based on http://inventwithpython.com/blogstatic/floodfill/roomcounter.py\n",
    "\n",
    "def floodFill(world, x, y, oldChar, newChar):\n",
    "    \n",
    "    # The recursive algorithm. Starting at x and y, changes any adjacent\n",
    "    # characters that match oldChar to newChar.\n",
    "    \n",
    "    worldWidth = len(world)\n",
    "    worldHeight = len(world[0])\n",
    "\n",
    "    if oldChar == None:\n",
    "        oldChar = world[x][y]\n",
    "\n",
    "    if world[x][y] != oldChar:\n",
    "        # Base case. If the current x, y character is not the oldChar,\n",
    "        # then do nothing.\n",
    "        return\n",
    "\n",
    "    # Change the character at world[x][y] to newChar\n",
    "    world[x][y] = newChar\n",
    "\n",
    "    # Recursive calls. Make a recursive call as long as we are not on the\n",
    "    # boundary (which would cause an Index Error.)\n",
    "    if x > 0: # left\n",
    "        floodFill(world, x-1, y, oldChar, newChar)\n",
    "\n",
    "    if y > 0: # up\n",
    "        floodFill(world, x, y-1, oldChar, newChar)\n",
    "\n",
    "    if x < worldWidth-1: # right\n",
    "        floodFill(world, x+1, y, oldChar, newChar)\n",
    "\n",
    "    if y < worldHeight-1: # down\n",
    "        floodFill(world, x, y+1, oldChar, newChar)\n",
    "        \n",
    "def getNumOfRooms(world):\n",
    "    worldWidth = len(world)\n",
    "    worldHeight = len(world[0])\n",
    "\n",
    "    roomCount = -1 # because the outside area counts as room, so let's start\n",
    "                   # off at -1.\n",
    "    for x in range(worldWidth):\n",
    "        for y in range(worldHeight):\n",
    "            # on each possible x, y empty space in the map, call floodfill.\n",
    "            if world[x][y] == 0:\n",
    "                floodFill(world, x, y, 0, 1)\n",
    "                roomCount += 1\n",
    "    return roomCount\n",
    "\n",
    "# Original data\n",
    "\n",
    "def GetBernoulliAccuracy(train_data,train_labels,dev_data,dev_labels):\n",
    "    bernnoulli = BernoulliNB(binarize=.1)\n",
    "    bernnoulli.fit(train_data, train_labels)\n",
    "    prediction = bernnoulli.predict(dev_data)\n",
    "    matches = prediction == dev_labels\n",
    "    accuracy = np.mean(matches)\n",
    "    return(accuracy)\n",
    "\n",
    "# pixel sum feature\n",
    "\n",
    "def AddCountPixel(digit):\n",
    "    DigitCopy = np.reshape(digit,(28,28))\n",
    "    RowSum = DigitCopy.sum(axis=1)\n",
    "    ColSum = DigitCopy.sum(axis=0)\n",
    "    digit = np.append(digit,RowSum)\n",
    "    digit = np.append(digit,ColSum)\n",
    "    return(digit)\n",
    "\n",
    "# Room Count Feature\n",
    "\n",
    "def AddRoomCount(digit):\n",
    "    import copy\n",
    "    DigitCopy = np.reshape(digit,(28,28))\n",
    "    regions = getNumOfRooms(copy.deepcopy(DigitCopy))\n",
    "    digit = np.append(digit,regions)\n",
    "    return(digit)\n",
    "\n",
    "#Adding Both Feature\n",
    "def AddBoth(digit):\n",
    "    import copy\n",
    "    DigitCopy = np.reshape(digit,(28,28))\n",
    "    RowSum = DigitCopy.sum(axis=1)\n",
    "    ColSum = DigitCopy.sum(axis=0)\n",
    "    regions = getNumOfRooms(copy.deepcopy(DigitCopy))\n",
    "    digit = np.append(digit,regions)\n",
    "    digit = np.append(digit,RowSum)\n",
    "    digit = np.append(digit,ColSum)\n",
    "    return(digit)\n",
    "    \n",
    "\n",
    "# add new features to create training data\n",
    "    \n",
    "def P12():\n",
    "    # Add Count Pixel Only\n",
    "    MiniTrainAddPixelCountOnly = np.array([AddCountPixel(digit) for digit in mini_train_data])\n",
    "    DevPlusAddPixelCountOnly = np.array([AddCountPixel(digit) for digit in dev_data])\n",
    "    \n",
    "    print(\"Original Accuracy:\", str(GetBernoulliAccuracy(mini_train_data,mini_train_labels,dev_data,dev_labels)))\n",
    "    print(\"Adding Pixel Count Accuray:\", str(GetBernoulliAccuracy(MiniTrainAddPixelCountOnly,\n",
    "                                                                  mini_train_labels,DevPlusAddPixelCountOnly,\n",
    "                                                                  dev_labels)))\n",
    "    print(\"Adding count pixel improves the accuracy by:\",\n",
    "          str(GetBernoulliAccuracy(MiniTrainAddPixelCountOnly,\n",
    "                                   mini_train_labels,DevPlusAddPixelCountOnly,dev_labels) - \n",
    "              GetBernoulliAccuracy(mini_train_data,mini_train_labels,dev_data,dev_labels)))\n",
    "    \n",
    "    # Add Count Room Only\n",
    "    MiniTrainAddRoomCountOnly = np.array([AddRoomCount(digit) for digit in mini_train_data])\n",
    "    DevPlusAddRoomCountOnly = np.array([AddRoomCount(digit) for digit in dev_data])\n",
    "    \n",
    "    print(\"Original Accuracy:\", str(GetBernoulliAccuracy(mini_train_data,mini_train_labels,dev_data,dev_labels)))\n",
    "    print(\"Adding count room  Accuray:\", str(GetBernoulliAccuracy(MiniTrainAddRoomCountOnly,\n",
    "                                                                  mini_train_labels,DevPlusAddRoomCountOnly,\n",
    "                                                                  dev_labels)))\n",
    "    \n",
    "    print(\"Adding count room improves the accuracy by:\",\n",
    "          str(GetBernoulliAccuracy(MiniTrainAddRoomCountOnly,\n",
    "                                   mini_train_labels,DevPlusAddRoomCountOnly,dev_labels) - \n",
    "              GetBernoulliAccuracy(mini_train_data,mini_train_labels,dev_data,dev_labels)))\n",
    "    \n",
    "    # Add both features\n",
    "    MiniTrainAddBoth = np.array([AddBoth(digit) for digit in mini_train_data])\n",
    "    DevPlusBoth= np.array([AddBoth(digit) for digit in dev_data])\n",
    "    \n",
    "    print(\"Original Accuracy:\", str(GetBernoulliAccuracy(mini_train_data,mini_train_labels,dev_data,dev_labels)))\n",
    "    print(\"Adding Both Accuray:\", str(GetBernoulliAccuracy(MiniTrainAddBoth,\n",
    "                                                                  mini_train_labels,DevPlusBoth,\n",
    "                                                                  dev_labels)))\n",
    "    \n",
    "    print(\"Adding both improves the accuracy by:\",\n",
    "          str(GetBernoulliAccuracy(MiniTrainAddBoth,\n",
    "                                   mini_train_labels,DevPlusBoth,dev_labels) - \n",
    "              GetBernoulliAccuracy(mini_train_data,mini_train_labels,dev_data,dev_labels)))\n",
    "    \n",
    "    #check\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "P12()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that both features are able to improve the accuray by similar amount. \n",
    "And when they are used together, the increase in accuracy is increased by the aggregrated improve when used seperately"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
